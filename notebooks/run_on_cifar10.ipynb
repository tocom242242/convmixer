{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "944eebbe-2a4e-4750-a3c8-ed63d3aec781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Epoch [1/5] Loss: 2.3152414113283157\n",
      "Epoch [2/5] Loss: 2.2485316582024097\n",
      "Epoch [3/5] Loss: 2.2066088914871216\n",
      "Epoch [4/5] Loss: 2.171963505446911\n",
      "Epoch [5/5] Loss: 2.1313756853342056\n",
      "Accuracy: 19.6%\n"
     ]
    }
   ],
   "source": [
    "from convmixer.convmixer import ConvMixer\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from convmixer.convmixer import ConvMixer\n",
    "from convmixer.simple_model import SimpleCNN\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "train_size = 1000\n",
    "test_size = 1000\n",
    "\n",
    "transform_cifar = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "        ),  # 3 channels for CIFAR-10\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset_cifar = datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform_cifar\n",
    ")\n",
    "test_dataset_cifar = datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, transform=transform_cifar\n",
    ")\n",
    "\n",
    "train_indices_cifar = torch.randperm(len(train_dataset_cifar))[:train_size]\n",
    "test_indices_cifar = torch.randperm(len(test_dataset_cifar))[:test_size]\n",
    "\n",
    "train_subset_cifar = Subset(train_dataset_cifar, train_indices_cifar)\n",
    "test_subset_cifar = Subset(test_dataset_cifar, test_indices_cifar)\n",
    "\n",
    "train_loader_cifar = DataLoader(train_subset_cifar, batch_size=32, shuffle=True)\n",
    "test_loader_cifar = DataLoader(test_subset_cifar, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "def main():\n",
    "    model_cifar = ConvMixer(3, 3)\n",
    "    # 損失関数と最適化手法を定義\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model_cifar.parameters(), lr=0.001)\n",
    "    # モデルのインスタンスを作成\n",
    "\n",
    "    # トレーニングと評価を実行\n",
    "    train(model_cifar, train_loader_cifar, criterion, optimizer, epochs=5)\n",
    "    accuracy_cifar = evaluate(model_cifar, test_loader_cifar)\n",
    "    accuracy_cifar\n",
    "\n",
    "\n",
    "# トレーニングの関数を定義\n",
    "def train(model, train_loader, criterion, optimizer, epochs=1):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] Loss: {total_loss/len(train_loader)}\")\n",
    "\n",
    "\n",
    "# モデルの評価関数を定義\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            outputs = model(data)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    accuracy = 100.0 * correct / len(test_loader.dataset)\n",
    "    print(f\"Accuracy: {accuracy}%\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
